{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPD1GHIdCw29fnVZDq+ONc8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awildt01/prophet/blob/main/pdf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akMvdJGMQSrG",
        "outputId": "27659c5d-46df-42a8-cdf7-b1c4003dd84f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf2 in /usr/local/lib/python3.11/dist-packages (2.8.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (11.1.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (4.56.0)\n"
          ]
        }
      ],
      "source": [
        "pip install --upgrade fpdf2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installiere fpdf2\n",
        "!pip install fpdf2\n",
        "\n",
        "from fpdf import FPDF\n",
        "\n",
        "# Initialize PDF\n",
        "pdf = FPDF()\n",
        "pdf.add_page()\n",
        "\n",
        "# Set a font that supports Unicode (e.g., Arial)\n",
        "pdf.add_font('Arial', '', 'arial.ttf', uni=True)  # Verwende eine Unicode-Schriftart\n",
        "pdf.set_font('Arial', size=12)\n",
        "\n",
        "# Text content\n",
        "text = \"\"\"\n",
        "1. Normalisierung und Skalierung:\n",
        "\n",
        "Ziel: Daten auf eine einheitliche Skala bringen, um Verzerrungen durch unterschiedliche Größenordnungen zu vermeiden.\n",
        "\n",
        "Beispiele:\n",
        "- Min-Max-Skalierung: Transformiert die Daten in einen Bereich zwischen 0 und 1.\n",
        "  Formel: X_normalized = (X - X_min) / (X_max - X_min)\n",
        "\n",
        "- Z-Score-Standardisierung: Transformiert die Daten so, dass sie einen Mittelwert von 0 und eine Standardabweichung von 1 haben.\n",
        "  Formel: X_standardized = (X - μ) / σ\n",
        "\n",
        "- Robust Scaling: Verwendet den Median und den Interquartilsabstand (IQR), um Ausreißer zu reduzieren.\n",
        "  Formel: X_robust = (X - Median) / IQR\n",
        "\n",
        "---\n",
        "\n",
        "2. Aggregation:\n",
        "\n",
        "Ziel: Daten zusammenfassen, um Muster auf höherer Ebene zu erkennen.\n",
        "\n",
        "Beispiele:\n",
        "- Zeitliche Aggregation: Tägliche Verkaufsdaten in monatliche oder jährliche Summen umwandeln.\n",
        "- Gruppierung: Daten nach Kategorien gruppieren, z. B. durchschnittliche Verkäufe pro Region oder Produktkategorie.\n",
        "- Rollierende Durchschnitte: Gleitende Durchschnitte berechnen, um Trends zu glätten.\n",
        "\n",
        "---\n",
        "\n",
        "3. Kodierung kategorischer Variablen:\n",
        "\n",
        "Ziel: Kategorische Daten in numerische Werte umwandeln, damit sie von Algorithmen verarbeitet werden können.\n",
        "\n",
        "Beispiele:\n",
        "- One-Hot-Encoding: Erstellt binäre Spalten für jede Kategorie.\n",
        "- Label-Encoding: Weist jeder Kategorie eine eindeutige Zahl zu.\n",
        "- Target Encoding: Ersetzt Kategorien durch den Durchschnittswert der Zielvariable für diese Kategorie.\n",
        "\n",
        "---\n",
        "\n",
        "4. Feature-Engineering:\n",
        "\n",
        "Ziel: Neue Variablen aus vorhandenen Daten erstellen, um die Modellleistung zu verbessern.\n",
        "\n",
        "Beispiele:\n",
        "- Interaktionsterme: Kombination von Variablen, z. B. Alter * Einkommen.\n",
        "- Polynomiale Features: Erstellen von quadratischen oder kubischen Termen, z. B. X^2 oder X^3.\n",
        "- Zeitbasierte Features: Extraktion von Wochentagen, Monaten oder Feiertagen aus Datumsangaben.\n",
        "\n",
        "---\n",
        "\n",
        "5. Behandlung von fehlenden Werten:\n",
        "\n",
        "Ziel: Fehlende Daten ersetzen oder entfernen, um die Datenqualität zu verbessern.\n",
        "\n",
        "Beispiele:\n",
        "- Imputation: Ersetzen fehlender Werte durch Mittelwert, Median oder Modus.\n",
        "- Vorwärts- oder Rückwärtsfüllung: Verwenden von vorherigen oder nachfolgenden Werten in Zeitreihen.\n",
        "- Erstellen einer Indikatorvariable: Hinzufügen einer binären Spalte, die anzeigt, ob ein Wert fehlt.\n",
        "\n",
        "---\n",
        "\n",
        "6. Transformation von Zeitreihen:\n",
        "\n",
        "Ziel: Zeitreihendaten für die Analyse vorbereiten.\n",
        "\n",
        "Beispiele:\n",
        "- Differenzierung: Berechnen der Differenz zwischen aufeinanderfolgenden Werten, um Trends zu entfernen.\n",
        "- Log-Transformation: Anwenden des natürlichen Logarithmus, um die Skala zu stabilisieren.\n",
        "- Saisonale Zerlegung: Trennen der Daten in Trend, Saison und Rauschen.\n",
        "\n",
        "---\n",
        "\n",
        "7. Binning (Diskretisierung):\n",
        "\n",
        "Ziel: Kontinuierliche Variablen in Intervalle unterteilen.\n",
        "\n",
        "Beispiele:\n",
        "- Gleichmäßige Intervalle: Unterteilung in gleich große Bereiche, z. B. Alter in 10-Jahres-Intervalle.\n",
        "- Quantilbasiert: Unterteilung basierend auf der Verteilung der Daten, z. B. in Quartile oder Dezile.\n",
        "\n",
        "---\n",
        "\n",
        "8. Textdaten-Transformation:\n",
        "\n",
        "Ziel: Textdaten in numerische Form umwandeln, um sie analysieren zu können.\n",
        "\n",
        "Beispiele:\n",
        "- TF-IDF (Term Frequency-Inverse Document Frequency): Misst die Wichtigkeit von Wörtern in einem Dokument.\n",
        "- Word Embeddings: Verwendung von Modellen wie Word2Vec oder GloVe, um Wörter in Vektoren umzuwandeln.\n",
        "- Tokenisierung: Aufteilen von Text in einzelne Wörter oder Sätze.\n",
        "\n",
        "---\n",
        "\n",
        "9. Dimensionsreduktion:\n",
        "\n",
        "Ziel: Die Anzahl der Variablen reduzieren, um die Komplexität zu verringern.\n",
        "\n",
        "Beispiele:\n",
        "- PCA (Principal Component Analysis): Reduziert die Dimensionalität durch lineare Transformation.\n",
        "- t-SNE (t-Distributed Stochastic Neighbor Embedding): Visualisierung hochdimensionaler Daten in 2D oder 3D.\n",
        "- Feature-Auswahl: Entfernen unwichtiger Variablen basierend auf statistischen Tests oder Modellleistung.\n",
        "\n",
        "---\n",
        "\n",
        "10. Transformation von Verteilungen:\n",
        "\n",
        "Ziel: Daten so transformieren, dass sie einer Normalverteilung ähneln.\n",
        "\n",
        "Beispiele:\n",
        "- Log-Transformation: Anwenden des natürlichen Logarithmus auf schiefe Daten.\n",
        "- Box-Cox-Transformation: Eine Familie von Transformationen, um Nicht-Normalität zu korrigieren.\n",
        "- Exponential-Transformation: Anwenden der Exponentialfunktion auf Daten mit negativer Schiefe.\n",
        "\n",
        "---\n",
        "\n",
        "Fazit:\n",
        "\n",
        "Die Transformation von Daten ist ein vielseitiger Prozess, der je nach Art der Daten und den Anforderungen der Analyse oder Modellierung unterschiedliche Techniken erfordert. Die Wahl der richtigen Transformation kann die Qualität der Daten erheblich verbessern und die Leistung von Machine-Learning-Modellen steigern.\n",
        "\"\"\"\n",
        "\n",
        "# Add text to PDF\n",
        "pdf.multi_cell(0, 10, text)\n",
        "\n",
        "# Save PDF\n",
        "pdf_file = \"Data_Transformation_Techniques.pdf\"\n",
        "pdf.output(pdf_file)\n",
        "\n",
        "print(f\"PDF saved as {pdf_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4T85MVEi1ahA",
        "outputId": "2e9e1bef-c9f9-46d4-8b87-df5f3a6d595b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf2 in /usr/local/lib/python3.11/dist-packages (2.8.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2) (0.7.1)\n",
            "Requirement already satisfied: Pillow!=9.2.*,>=6.2.2 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (11.1.0)\n",
            "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from fpdf2) (4.56.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-7bb3fbcbc2d8>:11: DeprecationWarning: \"uni\" parameter is deprecated since v2.5.1, unused and will soon be removed\n",
            "  pdf.add_font('Arial', '', 'arial.ttf', uni=True)  # Verwende eine Unicode-Schriftart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF saved as Data_Transformation_Techniques.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installiere reportlab\n",
        "!pip install reportlab\n",
        "\n",
        "from reportlab.lib.pagesizes import letter\n",
        "from reportlab.lib import colors\n",
        "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
        "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer\n",
        "\n",
        "# PDF-Datei erstellen\n",
        "pdf_file = \"Data_Transformation_Techniques_3.pdf\"\n",
        "pdf = SimpleDocTemplate(pdf_file, pagesize=letter)\n",
        "\n",
        "# Stile definieren\n",
        "styles = getSampleStyleSheet()\n",
        "title_style = styles['Title']\n",
        "heading_style = styles['Heading2']\n",
        "body_style = ParagraphStyle(\n",
        "    'Body',\n",
        "    parent=styles['BodyText'],\n",
        "    spaceBefore=6,\n",
        "    spaceAfter=6,\n",
        "    fontSize=12,\n",
        "    leading=14,\n",
        ")\n",
        "\n",
        "# Textinhalt\n",
        "content = []\n",
        "\n",
        "# Titel\n",
        "title = Paragraph(\"Daten-Transformationstechniken\", title_style)\n",
        "content.append(title)\n",
        "content.append(Spacer(1, 12))\n",
        "\n",
        "# Abschnitte\n",
        "sections = [\n",
        "    {\n",
        "        \"title\": \"1. Normalisierung und Skalierung\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Daten auf eine einheitliche Skala bringen, um Verzerrungen durch unterschiedliche Größenordnungen zu vermeiden.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Min-Max-Skalierung:</b> Transformiert die Daten in einen Bereich zwischen 0 und 1.<br/>\n",
        "          Formel: X_normalized = (X - X_min) / (X_max - X_min)<br/>\n",
        "        - <b>Z-Score-Standardisierung:</b> Transformiert die Daten so, dass sie einen Mittelwert von 0 und eine Standardabweichung von 1 haben.<br/>\n",
        "          Formel: X_standardized = (X - μ) / σ<br/>\n",
        "        - <b>Robust Scaling:</b> Verwendet den Median und den Interquartilsabstand (IQR), um Ausreißer zu reduzieren.<br/>\n",
        "          Formel: X_robust = (X - Median) / IQR<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"2. Aggregation\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Daten zusammenfassen, um Muster auf höherer Ebene zu erkennen.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Zeitliche Aggregation:</b> Tägliche Verkaufsdaten in monatliche oder jährliche Summen umwandeln.<br/>\n",
        "        - <b>Gruppierung:</b> Daten nach Kategorien gruppieren, z. B. durchschnittliche Verkäufe pro Region oder Produktkategorie.<br/>\n",
        "        - <b>Rollierende Durchschnitte:</b> Gleitende Durchschnitte berechnen, um Trends zu glätten.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"3. Kodierung kategorischer Variablen\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Kategorische Daten in numerische Werte umwandeln, damit sie von Algorithmen verarbeitet werden können.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>One-Hot-Encoding:</b> Erstellt binäre Spalten für jede Kategorie.<br/>\n",
        "        - <b>Label-Encoding:</b> Weist jeder Kategorie eine eindeutige Zahl zu.<br/>\n",
        "        - <b>Target Encoding:</b> Ersetzt Kategorien durch den Durchschnittswert der Zielvariable für diese Kategorie.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"4. Feature-Engineering\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Neue Variablen aus vorhandenen Daten erstellen, um die Modellleistung zu verbessern.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Interaktionsterme:</b> Kombination von Variablen, z. B. Alter * Einkommen.<br/>\n",
        "        - <b>Polynomiale Features:</b> Erstellen von quadratischen oder kubischen Termen, z. B. X^2 oder X^3.<br/>\n",
        "        - <b>Zeitbasierte Features:</b> Extraktion von Wochentagen, Monaten oder Feiertagen aus Datumsangaben.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"5. Behandlung von fehlenden Werten\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Fehlende Daten ersetzen oder entfernen, um die Datenqualität zu verbessern.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Imputation:</b> Ersetzen fehlender Werte durch Mittelwert, Median oder Modus.<br/>\n",
        "        - <b>Vorwärts- oder Rückwärtsfüllung:</b> Verwenden von vorherigen oder nachfolgenden Werten in Zeitreihen.<br/>\n",
        "        - <b>Erstellen einer Indikatorvariable:</b> Hinzufügen einer binären Spalte, die anzeigt, ob ein Wert fehlt.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"6. Transformation von Zeitreihen\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Zeitreihendaten für die Analyse vorbereiten.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Differenzierung:</b> Berechnen der Differenz zwischen aufeinanderfolgenden Werten, um Trends zu entfernen.<br/>\n",
        "        - <b>Log-Transformation:</b> Anwenden des natürlichen Logarithmus, um die Skala zu stabilisieren.<br/>\n",
        "        - <b>Saisonale Zerlegung:</b> Trennen der Daten in Trend, Saison und Rauschen.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"7. Binning (Diskretisierung)\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Kontinuierliche Variablen in Intervalle unterteilen.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Gleichmäßige Intervalle:</b> Unterteilung in gleich große Bereiche, z. B. Alter in 10-Jahres-Intervalle.<br/>\n",
        "        - <b>Quantilbasiert:</b> Unterteilung basierend auf der Verteilung der Daten, z. B. in Quartile oder Dezile.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"8. Textdaten-Transformation\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Textdaten in numerische Form umwandeln, um sie analysieren zu können.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>TF-IDF (Term Frequency-Inverse Document Frequency):</b> Misst die Wichtigkeit von Wörtern in einem Dokument.<br/>\n",
        "        - <b>Word Embeddings:</b> Verwendung von Modellen wie Word2Vec oder GloVe, um Wörter in Vektoren umzuwandeln.<br/>\n",
        "        - <b>Tokenisierung:</b> Aufteilen von Text in einzelne Wörter oder Sätze.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"9. Dimensionsreduktion\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Die Anzahl der Variablen reduzieren, um die Komplexität zu verringern.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>PCA (Principal Component Analysis):</b> Reduziert die Dimensionalität durch lineare Transformation.<br/>\n",
        "        - <b>t-SNE (t-Distributed Stochastic Neighbor Embedding):</b> Visualisierung hochdimensionaler Daten in 2D oder 3D.<br/>\n",
        "        - <b>Feature-Auswahl:</b> Entfernen unwichtiger Variablen basierend auf statistischen Tests oder Modellleistung.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"10. Transformation von Verteilungen\",\n",
        "        \"content\": \"\"\"\n",
        "        <b>Ziel:</b> Daten so transformieren, dass sie einer Normalverteilung ähneln.<br/><br/>\n",
        "        <b>Beispiele:</b><br/>\n",
        "        - <b>Log-Transformation:</b> Anwenden des natürlichen Logarithmus auf schiefe Daten.<br/>\n",
        "        - <b>Box-Cox-Transformation:</b> Eine Familie von Transformationen, um Nicht-Normalität zu korrigieren.<br/>\n",
        "        - <b>Exponential-Transformation:</b> Anwenden der Exponentialfunktion auf Daten mit negativer Schiefe.<br/>\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Fazit\",\n",
        "        \"content\": \"\"\"\n",
        "        Die Transformation von Daten ist ein vielseitiger Prozess, der je nach Art der Daten und den Anforderungen der Analyse oder Modellierung unterschiedliche Techniken erfordert. Die Wahl der richtigen Transformation kann die Qualität der Daten erheblich verbessern und die Leistung von Machine-Learning-Modellen steigern.\n",
        "        \"\"\"\n",
        "    },\n",
        "]\n",
        "\n",
        "# Abschnitte zum PDF hinzufügen\n",
        "for section in sections:\n",
        "    title = Paragraph(section[\"title\"], heading_style)\n",
        "    content.append(title)\n",
        "    content.append(Spacer(1, 6))\n",
        "    body = Paragraph(section[\"content\"], body_style)\n",
        "    content.append(body)\n",
        "    content.append(Spacer(1, 12))\n",
        "\n",
        "# PDF erstellen\n",
        "pdf.build(content)\n",
        "\n",
        "print(f\"PDF saved as {pdf_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q216FCFC6pJJ",
        "outputId": "c4f98ae7-b36f-43fe-8f21-6d00ed4e37b3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: reportlab in /usr/local/lib/python3.11/dist-packages (4.3.1)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.1.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
            "PDF saved as Data_Transformation_Techniques_3.pdf\n"
          ]
        }
      ]
    }
  ]
}